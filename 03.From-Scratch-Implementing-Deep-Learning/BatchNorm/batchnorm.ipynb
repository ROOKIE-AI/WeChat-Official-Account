{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从零实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm:\n",
    "    def __init__(self, num_features, momentum=0.9, epsilon=1e-5):\n",
    "        self.gamma = np.ones(num_features)  # 缩放参数\n",
    "        self.beta = np.zeros(num_features)   # 移位参数\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.running_mean = np.zeros(num_features)\n",
    "        self.running_var = np.ones(num_features)\n",
    "        self.training = True  # 标志是否在训练模式\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # 计算当前批次的均值和方差\n",
    "            batch_mean = np.mean(x, axis=0)\n",
    "            batch_var = np.var(x, axis=0)\n",
    "\n",
    "            # 更新运行均值和方差\n",
    "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * batch_mean\n",
    "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * batch_var\n",
    "\n",
    "            # 归一化\n",
    "            x_normalized = (x - batch_mean) / np.sqrt(batch_var + self.epsilon)\n",
    "        else:\n",
    "            # 使用运行均值和方差\n",
    "            x_normalized = (x - self.running_mean) / np.sqrt(self.running_var + self.epsilon)\n",
    "\n",
    "        return self.gamma * x_normalized + self.beta  # 缩放和移位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练模式输出:\\n [[-0.20879924  1.82754911  0.9557318   0.04413511 -0.79327021]\n",
      " [-0.98663681 -1.0839743   1.40712816  0.05559572  1.26379352]\n",
      " [-1.46858203  1.89015986  1.29364678 -1.75818707 -0.69711066]\n",
      " [-0.88908042 -0.28107046  0.25857334 -0.73364462 -0.28944876]\n",
      " [ 0.63583362 -0.81843577 -0.52394557 -1.03961429  0.32478129]\n",
      " [ 1.25271721 -0.62214491  0.22317678  0.01500495 -1.20154341]\n",
      " [ 0.62050063 -0.71722332 -1.28789917  1.67807333  2.22351172]\n",
      " [ 1.33536572 -0.27985864 -1.17816194  0.44337187  0.26546953]\n",
      " [-1.10749248  0.34170754 -1.39105144  1.4934874  -0.41036084]\n",
      " [ 0.81617381 -0.25670911  0.24280127 -0.1982224  -0.68582218]]\n",
      "推理模式输出:\\n [[ 0.34761317  0.95600362  0.72084368  0.56748504  0.12507165]\n",
      " [ 0.11825073  0.01996812  0.86159417  0.57006785  0.70467022]\n",
      " [-0.02386137  0.97613256  0.82620939  0.16130611  0.15216558]\n",
      " [ 0.14701737  0.27809639  0.50346179  0.39220132  0.26702845]\n",
      " [ 0.59667166  0.105337    0.25946354  0.3232467   0.440094  ]\n",
      " [ 0.77857329  0.16844321  0.49242474  0.56092014  0.01003654]\n",
      " [ 0.59215039  0.13787613  0.02125416  0.93571624  0.97508055]\n",
      " [ 0.80294401  0.27848598  0.05547147  0.65745871  0.42338231]\n",
      " [ 0.08261379  0.47831539 -0.01090989  0.89411717  0.23296025]\n",
      " [ 0.64984891  0.2859284   0.49854388  0.51286633  0.15534622]]\n"
     ]
    }
   ],
   "source": [
    "# 模拟数据输入\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(10, 5)  # 10个样本，5个特征\n",
    "\n",
    "# 创建BatchNorm实例\n",
    "batch_norm = BatchNorm(num_features=5)\n",
    "\n",
    "# 训练模式\n",
    "output_train = batch_norm.forward(data)\n",
    "print(\"训练模式输出:\\\\n\", output_train)\n",
    "\n",
    "# 切换到推理模式\n",
    "batch_norm.training = False\n",
    "output_infer = batch_norm.forward(data)  # 推理阶段使用训练得到的均值和方差\n",
    "print(\"推理模式输出:\\\\n\", output_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 框架实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(10, 50, bias=False), nn.BatchNorm1d(50), nn.ReLU(),\n",
    "    nn.Linear(50, 20, bias=False), nn.BatchNorm1d(20), nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个模型实例  \n",
    "model = net  \n",
    "\n",
    "# 定义损失函数  \n",
    "criterion = nn.MSELoss()  # 均方误差损失  \n",
    "\n",
    "# 定义优化器  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # 使用 SGD 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.7255\n",
      "Epoch [20/100], Loss: 0.6408\n",
      "Epoch [30/100], Loss: 0.5818\n",
      "Epoch [40/100], Loss: 0.5271\n",
      "Epoch [50/100], Loss: 0.4738\n",
      "Epoch [60/100], Loss: 0.4246\n",
      "Epoch [70/100], Loss: 0.3807\n",
      "Epoch [80/100], Loss: 0.3407\n",
      "Epoch [90/100], Loss: 0.3058\n",
      "Epoch [100/100], Loss: 0.2747\n"
     ]
    }
   ],
   "source": [
    "# 模拟一些随机数据作为输入和目标  \n",
    "input_data = torch.randn(100, 10)  # 100个样本，每个样本10个特征  \n",
    "target_data = torch.randn(100, 1)   # 100个目标值  \n",
    "\n",
    "# 训练模型  \n",
    "for epoch in range(100):  # 训练100个epoch  \n",
    "    model.train()  # 设置模型为训练模式  \n",
    "    \n",
    "    # 前向传播  \n",
    "    optimizer.zero_grad()  # 清空梯度  \n",
    "    output = model(input_data)  # 计算输出  \n",
    "    loss = criterion(output, target_data)  # 计算损失  \n",
    "    \n",
    "    # 反向传播  \n",
    "    loss.backward()  # 计算梯度  \n",
    "    optimizer.step()  # 更新参数  \n",
    "\n",
    "    # 打印损失  \n",
    "    if (epoch + 1) % 10 == 0:  \n",
    "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理输出:\n",
      " tensor([[-0.2790],\n",
      "        [ 0.0336],\n",
      "        [-0.9290],\n",
      "        [ 0.4044],\n",
      "        [-0.6063]])\n"
     ]
    }
   ],
   "source": [
    "# 模型推理  \n",
    "model.eval()  # 切换到评估模式  \n",
    "with torch.no_grad():  # 不计算梯度  \n",
    "    test_input = torch.randn(5, 10)  # 测试5个样本  \n",
    "    test_output = model(test_input)  \n",
    "    print(\"推理输出:\\n\", test_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
